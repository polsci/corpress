{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Corpress functions. You can call any of these functions directly, but use the corpress function if you want to gather data and output a corpus in one step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import html\n",
    "import pandas as pd\n",
    "import csv\n",
    "from slugify import slugify\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "basepath_for_test_data = '../test_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "urls_for_testing = {\n",
    "    'has_link': {\n",
    "        'url': 'https://adho.org/',\n",
    "        'endpoint_type': 'posts',\n",
    "        'endpoint_url': 'https://adho.org/wp-json/wp/v2/posts',\n",
    "        'description': 'Example URL with a <link> tag broadcasting the REST API endpoint' \n",
    "    }, \n",
    "    'no_link': {\n",
    "        'url': 'https://www.whitehouse.gov/',\n",
    "        'endpoint_type': 'posts',\n",
    "        'endpoint_url': 'https://www.whitehouse.gov/wp-json/wp/v2/posts',\n",
    "        'description': 'Example URL with no <link> tag and no REST API endpoint' \n",
    "    }, \n",
    "    'api_link': {\n",
    "        'url': 'https://adho.org/wp-json/',\n",
    "        'endpoint_type': 'pages',\n",
    "        'endpoint_url': 'https://adho.org/wp-json/wp/v2/pages',\n",
    "        'description': 'Example URL, which is the REST API endpoint' \n",
    "    }, \n",
    "    'error_status': {\n",
    "        'url': 'https://httpstat.us/403',\n",
    "        'endpoint_type': 'posts',\n",
    "        'endpoint_url': None,\n",
    "        'description': 'Example URL, which returns an error status code' \n",
    "    }, \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_api_url(url: str, # the URL of the WordPress website \n",
    "                endpoint_type: str = 'posts', # posts or pages\n",
    "                headers: dict = None, # optional headers for requests\n",
    "                ): # None if no endpoint detected, otherwise returns the endpoint URL\n",
    "    \"\"\"Queries a URL to get the REST API route for the endpoint type provided. \"\"\"\n",
    "\n",
    "    if not headers:\n",
    "        headers = {}\n",
    "\n",
    "    endpoint_url = None\n",
    "        \n",
    "    if endpoint_type == 'posts':\n",
    "        endpoint = 'wp/v2/posts'\n",
    "    elif endpoint_type == 'pages':\n",
    "        endpoint = 'wp/v2/pages'\n",
    "    else:\n",
    "        logging.error('The endpoint must be posts or pages.')\n",
    "        return None\n",
    "\n",
    "    if url.endswith(endpoint):\n",
    "        logging.info(f'URL {endpoint_url} appears to be REST API {endpoint_type} route')\n",
    "        endpoint_url = url\n",
    "    else:\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            try:\n",
    "                json_data = response.json()\n",
    "                if 'routes' in json_data:\n",
    "                    endpoint_url = json_data['routes']['/' + endpoint]['_links']['self'][0]['href']\n",
    "                    logging.info('URL is REST API endpoint')\n",
    "                    logging.info(f'Extracted {endpoint_type} route {endpoint_url}')\n",
    "            except (requests.JSONDecodeError, KeyError) as e:\n",
    "                soup = BeautifulSoup(response.content, 'lxml')\n",
    "                link = soup.find('link', rel=\"https://api.w.org/\")\n",
    "                if link:\n",
    "                    if link['href'].endswith('/'):\n",
    "                        endpoint_url = link['href'] + endpoint\n",
    "                    else:\n",
    "                        endpoint_url = link['href'] + '/' + endpoint\n",
    "                    logging.info('Found REST API endpoint link')\n",
    "                    logging.info(f'Setting {endpoint_type} route {endpoint_url}')\n",
    "                else:\n",
    "                    if url.endswith('/'):\n",
    "                        endpoint_url = url + 'wp-json/' + endpoint\n",
    "                    else:\n",
    "                        endpoint_url = url + '/wp-json/' + endpoint\n",
    "                    logging.info('No REST API endpoint link in markup')\n",
    "                    logging.info(f'Guessing {endpoint_type} route based on URL {endpoint_url}')\n",
    "        except requests.HTTPError as e:\n",
    "            logging.error(f'{url} returned status code {response.status_code}')\n",
    "            \n",
    "    return endpoint_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 14:33:46 - INFO - Found REST API endpoint link\n",
      "2024-08-23 14:33:46 - INFO - Setting posts route https://adho.org/wp-json/wp/v2/posts\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "endpoint_url = get_api_url('https://adho.org/', 'posts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Example URL with a <link> tag broadcasting the REST API endpoint: https://adho.org/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 14:33:50 - INFO - Found REST API endpoint link\n",
      "2024-08-23 14:33:50 - INFO - Setting posts route https://adho.org/wp-json/wp/v2/posts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Example URL with no <link> tag and no REST API endpoint: https://www.whitehouse.gov/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 14:33:52 - INFO - No REST API endpoint link in markup\n",
      "2024-08-23 14:33:52 - INFO - Guessing posts route based on URL https://www.whitehouse.gov/wp-json/wp/v2/posts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Example URL, which is the REST API endpoint: https://adho.org/wp-json/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 14:33:55 - INFO - URL is REST API endpoint\n",
      "2024-08-23 14:33:55 - INFO - Extracted pages route https://adho.org/wp-json/wp/v2/pages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Example URL, which returns an error status code: https://httpstat.us/403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 14:33:57 - ERROR - https://httpstat.us/403 returned status code 403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "for key, data in urls_for_testing.items():\n",
    "    print(f\"Testing {data['description']}: {data['url']}\")\n",
    "    assert get_api_url(data['url'], data['endpoint_type']) == data['endpoint_url']\n",
    "    print()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_json(endpoint_url: str, # the URL of the WordPress REST API endpoint\n",
    "             endpoint_type: str = 'posts', # the type of data to download\n",
    "             headers: dict = None, # optional headers for requests\n",
    "             params: dict = None, # optional parameters to pass to the API\n",
    "             json_save_path: str = None, # path to save the JSON data \n",
    "             seconds_between_requests: int = 5, # number of seconds to wait between requests, must be at least 1\n",
    "             max_pages: int = None # maximum number of pages to download\n",
    "            ) -> bool: # True if successful, False otherwise \n",
    "    \"\"\"Download and save JSON data from a specific REST API endpoint. \"\"\"\n",
    "\n",
    "    if not endpoint_url:\n",
    "        logging.error('No endpoint URL provided')\n",
    "        return False\n",
    "    \n",
    "    if seconds_between_requests < 1:\n",
    "        seconds_between_requests = 1\n",
    "        logging.warning('Setting minimum seconds between requests to 1 as value provided is less than 1')\n",
    "    \n",
    "    if not params:\n",
    "        params = {}\n",
    "    \n",
    "    if not headers:\n",
    "        headers = {}\n",
    "\n",
    "    if not json_save_path:\n",
    "        logging.error('No path provided to save JSON data')\n",
    "        return False\n",
    "\n",
    "    if not os.path.exists(json_save_path):\n",
    "        os.makedirs(json_save_path)\n",
    "        logging.info(f'Created JSON save path: {json_save_path}')\n",
    "    else:\n",
    "        logging.info(f'Using JSON save path: {json_save_path}')\n",
    "\n",
    "    if endpoint_type == 'posts':\n",
    "        pass\n",
    "    elif endpoint_type == 'pages':\n",
    "        pass\n",
    "    else:\n",
    "        logging.error('The endpoint must be posts or pages.')\n",
    "        return False\n",
    "\n",
    "    if max_pages is not None:\n",
    "        logging.info(f'Max pages to retrieve from API is set: {max_pages}')\n",
    "\n",
    "    has_more = True\n",
    "    page = 1\n",
    "    total_pages = False\n",
    "    consecutive_errors = 0\n",
    "\n",
    "    while has_more == True:\n",
    "        try:\n",
    "            params['page'] = page\n",
    "            r = requests.get(endpoint_url, params=params, headers=headers)\n",
    "            \n",
    "            logging.info(f'Downloading {r.url}')\n",
    "            r.raise_for_status()\n",
    "\n",
    "            if total_pages == False:\n",
    "                total_pages = int(r.headers['X-WP-TotalPages'])\n",
    "                logging.info(f'Total pages to retrieve is {total_pages}')\n",
    "                digits = len(str(total_pages))\n",
    "\n",
    "            filename = os.path.join(json_save_path, f'{endpoint_type}-{page:0{digits}}.json')\n",
    "\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "                #logging.info(f'Saved to {filename}')\n",
    "\n",
    "            page += 1\n",
    "            if page > total_pages:\n",
    "                has_more = False\n",
    "\n",
    "            if max_pages is not None and page > max_pages:\n",
    "                has_more = False\n",
    "\n",
    "            consecutive_errors = 0\n",
    "        except requests.HTTPError as e:\n",
    "            logging.error(f'Error downloading page {page} from {endpoint_url}')\n",
    "            logging.error(f'Status code: {r.status_code}')\n",
    "            if page == 1:\n",
    "                logging.error('It appears that this website does not provide access to the REST API. Exiting.')\n",
    "            else:\n",
    "                logging.error('Exiting based on status code error. If this is a 403 or 400, it may be that the website is refusing repeated access to their REST API.')\n",
    "            return False\n",
    "        # exception for Timeout or ConnectionError\n",
    "        except (requests.Timeout, requests.ConnectionError) as e:\n",
    "            logging.error(f'Error downloading page {page} ({e}) from {endpoint_url}')\n",
    "            consecutive_errors += 1\n",
    "            if consecutive_errors > 3:\n",
    "                return False\n",
    "\n",
    "        time.sleep(seconds_between_requests)\n",
    "\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 14:19:01 - INFO - Using JSON save path: ../test_data/json/\n",
      "2024-08-23 14:19:01 - INFO - Max pages to retrieve from API is set: 2\n",
      "2024-08-23 14:19:03 - INFO - Downloading https://adho.org/wp-json/wp/v2/posts?page=1\n",
      "2024-08-23 14:19:03 - INFO - Total pages to retrieve is 21\n",
      "2024-08-23 14:19:10 - INFO - Downloading https://adho.org/wp-json/wp/v2/posts?page=2\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "json_save_path = os.path.join(basepath_for_test_data, 'json/')\n",
    "if not os.path.exists(json_save_path):\n",
    "    os.makedirs(json_save_path)\n",
    "# clean up files in test directory\n",
    "for file in os.listdir(os.path.join(json_save_path)):\n",
    "    os.remove(os.path.join(json_save_path, file))\n",
    "\n",
    "params = {}\n",
    "# test returns True\n",
    "assert get_json(endpoint_url = 'https://adho.org/wp-json/wp/v2/posts', params = params, json_save_path = json_save_path, max_pages=2) == True\n",
    "\n",
    "# check that there are two files in the test directory\n",
    "assert len(os.listdir(json_save_path)) == 2\n",
    "\n",
    "# test post file names\n",
    "assert os.path.exists(os.path.join(json_save_path, 'posts-01.json'))\n",
    "assert os.path.exists(os.path.join(json_save_path, 'posts-02.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_corpus(corpus_format: str = 'txt', # format of the corpus files, txt or csv\n",
    "                  json_save_path: str = None, # path to JSON data \n",
    "                  corpus_save_path: str = None, # path to save corpus in txt format\n",
    "                  csv_save_file: str = None, # path to CSV file to output corpus in CSV format (or metadata if txt corpus)\n",
    "                  include_title_in_text: bool = True # include the title in the text file \n",
    "                 ) -> bool: # True if successful, False if there are errors parsing the JSON \n",
    "    \"\"\"Create a corpus from downloaded JSON data in txt or csv format. \"\"\"\n",
    "\n",
    "    if corpus_format == 'txt':\n",
    "        columns = ['date', 'datetime', 'type', 'id', 'title', 'link', 'filename']\n",
    "        csv_file_type = 'metadata'\n",
    "    elif corpus_format == 'csv':\n",
    "        columns = ['date', 'datetime', 'type', 'id', 'title', 'link', 'text']\n",
    "        csv_file_type = 'corpus'\n",
    "    else:\n",
    "        logging.error('Corpus format must be txt or csv')\n",
    "        return False\n",
    "\n",
    "    logging.info(f'Creating corpus in {corpus_format} format')\n",
    "\n",
    "    if not json_save_path:\n",
    "        logging.error('No path provided to json data')\n",
    "        return False\n",
    "    else:\n",
    "        if not os.path.exists(json_save_path):\n",
    "            logging.error('Path to JSON data does not exist')\n",
    "            return False\n",
    "    \n",
    "    if corpus_format == 'txt':\n",
    "        if not corpus_save_path:\n",
    "            logging.error('No corpus save path provided')\n",
    "            return False\n",
    "        if not os.path.exists(corpus_save_path):\n",
    "            os.makedirs(corpus_save_path)\n",
    "            logging.info(f'Created corpus save path: {corpus_save_path}')\n",
    "        else:\n",
    "            logging.info(f'Using corpus save path: {corpus_save_path}')\n",
    "\n",
    "    if corpus_format == 'csv':\n",
    "        if not csv_save_file:\n",
    "            logging.error('No path provided to save CSV corpus')\n",
    "            return False\n",
    "    \n",
    "    if csv_save_file:\n",
    "        csv_save_path = os.path.dirname(csv_save_file)\n",
    "        if not os.path.exists(os.path.dirname(csv_save_path)):\n",
    "            os.makedirs(os.path.dirname(csv_save_path))\n",
    "            logging.info(f'Created path to save CSV corpus: {os.path.dirname(csv_save_path)}')\n",
    "\n",
    "    try:\n",
    "        # if csv_save_path is provided (regardless of format) create it and write first row\n",
    "        if csv_save_file:\n",
    "            logging.info(f'Creating CSV file for {csv_file_type}: {csv_save_file}')\n",
    "            fw = open(csv_save_file, 'w', encoding='utf-8')\n",
    "            writer = csv.writer(fw)\n",
    "            writer.writerow(columns)\n",
    " \n",
    "        file_list = glob.glob(json_save_path + '/*.json')\n",
    "        for file in file_list:\n",
    "            with open(file, 'r', encoding='utf-8') as f:\n",
    "                logging.info(f\"Processing JSON: {os.path.basename(file)}\")\n",
    "                data = json.load(f)\n",
    "                for article in data:\n",
    "                    title = html.unescape(article['title']['rendered'])\n",
    "                    filename = f\"{article['date'][0:10]}-{article['type']}-{article['id']}-{slugify(title, max_length=100)}.txt\"\n",
    "                    #logging.info(f\"Processing {article['type']}: {title}\")\n",
    "                    soup = BeautifulSoup(article['content']['rendered'], 'lxml')\n",
    "                    content = soup.get_text().strip()\n",
    "\n",
    "                    if csv_save_file:\n",
    "                        if corpus_format == 'csv':\n",
    "                            writer.writerow([article['date'][0:10], article['date'], article['type'], article['id'], article['link'], title, content])\n",
    "                        else:\n",
    "                            writer.writerow([article['date'][0:10], article['date'], article['type'], article['id'], article['link'], title, filename])\n",
    "                        \n",
    "                    if corpus_format == 'txt':\n",
    "                        #logging.info(f'Saving corpus file {filename}')\n",
    "                        with open(corpus_save_path + filename, 'w', encoding='utf-8') as txtfile:\n",
    "                            if include_title_in_text:\n",
    "                                txtfile.write(title + '\\n\\n')\n",
    "                            txtfile.write(content)\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f'Exception (JSONDecodeError) - error decoding JSON file: {os.path.basename(file)}')\n",
    "        return False\n",
    "    except KeyError as e:\n",
    "        logging.error(f'Exception (KeyError) - indicating unexpected JSON file content: {os.path.basename(file)}')\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logging.error(f'Exception - {e} - exiting by raising error ...')\n",
    "        raise\n",
    "    \n",
    "    return True\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 14:19:15 - INFO - Creating corpus in txt format\n",
      "2024-08-23 14:19:15 - INFO - Using corpus save path: ../test_data/txt/\n",
      "2024-08-23 14:19:15 - INFO - Processing JSON: posts-02.json\n",
      "2024-08-23 14:19:15 - INFO - Processing JSON: posts-01.json\n",
      "2024-08-23 14:19:15 - INFO - Creating corpus in txt format\n",
      "2024-08-23 14:19:15 - INFO - Using corpus save path: ../test_data/txt/\n",
      "2024-08-23 14:19:15 - INFO - Processing JSON: posts-001.json\n",
      "2024-08-23 14:19:15 - ERROR - Exception (JSONDecodeError) - error decoding JSON file: posts-001.json\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "json_save_path = os.path.join(basepath_for_test_data, 'json/')\n",
    "json_corrupt_save_path = os.path.join(basepath_for_test_data, 'json_corrupt/')\n",
    "corpus_save_path = os.path.join(basepath_for_test_data, 'txt/')\n",
    "metadata_csv_save_file = os.path.join(basepath_for_test_data, 'metadata/metadata.csv')\n",
    "corpus_csv_save_file = os.path.join(basepath_for_test_data, 'corpus/corpus.csv')\n",
    "\n",
    "# clean up files in test directory\n",
    "for file in os.listdir(corpus_save_path):\n",
    "    os.remove(os.path.join(corpus_save_path, file))\n",
    "for file in os.listdir(os.path.dirname(metadata_csv_save_file)):\n",
    "    os.remove(os.path.join(os.path.dirname(metadata_csv_save_file), file))\n",
    "for file in os.listdir(os.path.dirname(corpus_csv_save_file)):\n",
    "    os.remove(os.path.join(os.path.dirname(corpus_csv_save_file), file))\n",
    "\n",
    "assert create_corpus(\n",
    "        corpus_format = 'txt',\n",
    "        json_save_path = json_save_path, \n",
    "        corpus_save_path = corpus_save_path) == True\n",
    "\n",
    "# check that there are 20 files in the test directory\n",
    "assert len(os.listdir(corpus_save_path)) == 20\n",
    "\n",
    "# corrupt JSON file should return False\n",
    "assert create_corpus(\n",
    "        corpus_format = 'txt',\n",
    "        json_save_path = json_corrupt_save_path, \n",
    "        corpus_save_path = corpus_save_path) == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 14:19:15 - INFO - Creating corpus in csv format\n",
      "2024-08-23 14:19:15 - INFO - Creating CSV file for corpus: ../test_data/corpus/corpus.csv\n",
      "2024-08-23 14:19:15 - INFO - Processing JSON: posts-02.json\n",
      "2024-08-23 14:19:15 - INFO - Processing JSON: posts-01.json\n",
      "2024-08-23 14:19:15 - INFO - Creating corpus in txt format\n",
      "2024-08-23 14:19:15 - INFO - Using corpus save path: ../test_data/txt/\n",
      "2024-08-23 14:19:15 - INFO - Creating CSV file for metadata: ../test_data/metadata/metadata.csv\n",
      "2024-08-23 14:19:15 - INFO - Processing JSON: posts-02.json\n",
      "2024-08-23 14:19:15 - INFO - Processing JSON: posts-01.json\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "json_save_path = os.path.join(basepath_for_test_data, 'json/')\n",
    "corpus_save_path = os.path.join(basepath_for_test_data, 'txt/')\n",
    "metadata_csv_save_file = os.path.join(basepath_for_test_data, 'metadata/metadata.csv')\n",
    "corpus_csv_save_file = os.path.join(basepath_for_test_data, 'corpus/corpus.csv')\n",
    "\n",
    "# clean up files in test directory\n",
    "for file in os.listdir(corpus_save_path):\n",
    "    os.remove(os.path.join(corpus_save_path, file))\n",
    "for file in os.listdir(os.path.dirname(metadata_csv_save_file)):\n",
    "    os.remove(os.path.join(os.path.dirname(metadata_csv_save_file), file))\n",
    "for file in os.listdir(os.path.dirname(corpus_csv_save_file)):\n",
    "    os.remove(os.path.join(os.path.dirname(corpus_csv_save_file), file))\n",
    "\n",
    "# test CSV returns True\n",
    "assert create_corpus(corpus_format='csv', \n",
    "                     json_save_path=json_save_path, \n",
    "                     corpus_save_path=None, \n",
    "                     csv_save_file=corpus_csv_save_file) == True\n",
    "\n",
    "assert os.path.exists(corpus_csv_save_file)\n",
    "\n",
    "# test returns True\n",
    "assert create_corpus(corpus_format='txt', \n",
    "                     json_save_path=json_save_path, \n",
    "                     corpus_save_path=corpus_save_path, \n",
    "                     csv_save_file=metadata_csv_save_file) == True\n",
    "\n",
    "assert os.path.exists(metadata_csv_save_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def result_reporting(result: dict, # the result dictionary\n",
    "                     output: bool = True # output the results\n",
    "                     ) -> dict: # returns the result dictionary\n",
    "    \"\"\"Outputs the results of the corpress process\"\"\"\n",
    "\n",
    "    # output dataframe\n",
    "    df = pd.DataFrame(result.items(), columns=['Key', 'Value'])\n",
    "    \n",
    "    try: # if in a Jupyter notebook\n",
    "        display(df)\n",
    "    except NameError:\n",
    "        print(df)\n",
    "\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def corpress(url: str, # the URL of the WordPress website \n",
    "            endpoint_type: str = 'posts', # posts or pages\n",
    "            headers: dict = None, # optional headers for requests\n",
    "            params: dict = None, # optional parameters to pass to the API\n",
    "            corpus_format: str = 'txt', # format of the corpus files, txt or csv\n",
    "            json_save_path: str = None, # path to save the JSON data \n",
    "            corpus_save_path: str = None, # path to save the corpus in txt format\n",
    "            csv_save_file: str = None, # path to CSV file to output corpus in CSV format (or metadata if txt corpus)\n",
    "            seconds_between_requests: int = 5, # number of seconds to wait between requests\n",
    "            max_pages: int = None, # maximum number of pages to download\n",
    "            include_title_in_text: bool = True, # option to include the title in the text file \n",
    "            output: bool = True # option to output the results of the process\n",
    "            ) -> dict: # dictionary with results of each stage of the process and the number of texts in the corpus\n",
    "    \"\"\"Retrieve data from the REST API and create a corpus.\"\"\"\n",
    "    \n",
    "    result = {\n",
    "        'url': url,\n",
    "        'endpoint_url': None,\n",
    "        'headers': headers,\n",
    "        'params': None,\n",
    "        'get_api_url': False,\n",
    "        'get_json': False,\n",
    "        'create_corpus': False,\n",
    "        'corpus_format': corpus_format,\n",
    "        'corpus_save_path': corpus_save_path,\n",
    "        'csv_save_file': csv_save_file,\n",
    "        'corpus_texts_count': 0\n",
    "    }\n",
    "\n",
    "    # get the endpoint_url\n",
    "    endpoint_url = get_api_url(url, endpoint_type, headers)\n",
    "    \n",
    "    if not endpoint_url:\n",
    "        logging.error('No endpoint URL detected. Exiting.')\n",
    "        return result_reporting(result, output)\n",
    "    else:\n",
    "        result['get_api_url'] = True\n",
    "        result['endpoint_url'] = endpoint_url\n",
    "\n",
    "    # if params is a dict\n",
    "    if isinstance(params, dict):\n",
    "        result['params'] = params.copy()\n",
    "    \n",
    "    # download the data\n",
    "    get_json_result = get_json(endpoint_url, endpoint_type, headers, params, json_save_path, seconds_between_requests, max_pages)\n",
    "\n",
    "    if get_json_result == False:\n",
    "        logging.error('Error downloading data. Exiting.')\n",
    "        return result_reporting(result, output)\n",
    "    else:\n",
    "        result['get_json'] = True\n",
    "\n",
    "    # create the corpus\n",
    "    create_corpus_result = create_corpus(corpus_format, json_save_path, corpus_save_path, csv_save_file, include_title_in_text)\n",
    "\n",
    "    if create_corpus_result == False:\n",
    "        logging.error('Error creating corpus')\n",
    "        return result_reporting(result, output)\n",
    "    else:\n",
    "        result['create_corpus'] = True\n",
    "\n",
    "    if corpus_format == 'txt':\n",
    "        result['corpus_texts_count'] = len(os.listdir(corpus_save_path))\n",
    "    elif corpus_format == 'csv':\n",
    "        result['corpus_texts_count'] = len(pd.read_csv(csv_save_file))\n",
    "\n",
    "    return result_reporting(result, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 14:19:15 - INFO - No REST API endpoint link in markup\n",
      "2024-08-23 14:19:15 - INFO - Guessing posts route based on URL https://www.whitehouse.gov/wp-json/wp/v2/posts\n",
      "2024-08-23 14:19:15 - INFO - Using JSON save path: ../test_data/json/\n",
      "2024-08-23 14:19:15 - INFO - Max pages to retrieve from API is set: 2\n",
      "2024-08-23 14:19:16 - INFO - Downloading https://www.whitehouse.gov/wp-json/wp/v2/posts?page=1\n",
      "2024-08-23 14:19:16 - ERROR - Error downloading page 1 from https://www.whitehouse.gov/wp-json/wp/v2/posts\n",
      "2024-08-23 14:19:16 - ERROR - Status code: 403\n",
      "2024-08-23 14:19:16 - ERROR - It appears that this website does not provide access to the REST API. Exiting.\n",
      "2024-08-23 14:19:16 - ERROR - Error downloading data. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>url</td>\n",
       "      <td>https://www.whitehouse.gov/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>endpoint_url</td>\n",
       "      <td>https://www.whitehouse.gov/wp-json/wp/v2/posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>headers</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>params</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>get_api_url</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>get_json</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>create_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>corpus_format</td>\n",
       "      <td>txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>corpus_save_path</td>\n",
       "      <td>../test_data/txt/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>csv_save_file</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>corpus_texts_count</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Key                                           Value\n",
       "0                  url                     https://www.whitehouse.gov/\n",
       "1         endpoint_url  https://www.whitehouse.gov/wp-json/wp/v2/posts\n",
       "2              headers                                            None\n",
       "3               params                                            None\n",
       "4          get_api_url                                            True\n",
       "5             get_json                                           False\n",
       "6        create_corpus                                           False\n",
       "7        corpus_format                                             txt\n",
       "8     corpus_save_path                               ../test_data/txt/\n",
       "9        csv_save_file                                            None\n",
       "10  corpus_texts_count                                               0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 14:19:17 - INFO - Found REST API endpoint link\n",
      "2024-08-23 14:19:17 - INFO - Setting pages route https://adho.org/wp-json/wp/v2/pages\n",
      "2024-08-23 14:19:17 - INFO - Using JSON save path: ../test_data/json/\n",
      "2024-08-23 14:19:17 - INFO - Max pages to retrieve from API is set: 2\n",
      "2024-08-23 14:19:20 - INFO - Downloading https://adho.org/wp-json/wp/v2/pages?search=conference&page=1\n",
      "2024-08-23 14:19:20 - INFO - Total pages to retrieve is 5\n",
      "2024-08-23 14:19:27 - INFO - Downloading https://adho.org/wp-json/wp/v2/pages?search=conference&page=2\n",
      "2024-08-23 14:19:32 - INFO - Creating corpus in csv format\n",
      "2024-08-23 14:19:32 - INFO - Creating CSV file for corpus: ../test_data/corpus/corpus.csv\n",
      "2024-08-23 14:19:32 - INFO - Processing JSON: pages-2.json\n",
      "2024-08-23 14:19:32 - INFO - Processing JSON: pages-1.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>url</td>\n",
       "      <td>https://adho.org/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>endpoint_url</td>\n",
       "      <td>https://adho.org/wp-json/wp/v2/pages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>headers</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>params</td>\n",
       "      <td>{'search': 'conference'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>get_api_url</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>get_json</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>create_corpus</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>corpus_format</td>\n",
       "      <td>csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>corpus_save_path</td>\n",
       "      <td>../test_data/txt/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>csv_save_file</td>\n",
       "      <td>../test_data/corpus/corpus.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>corpus_texts_count</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Key                                 Value\n",
       "0                  url                     https://adho.org/\n",
       "1         endpoint_url  https://adho.org/wp-json/wp/v2/pages\n",
       "2              headers                                  None\n",
       "3               params              {'search': 'conference'}\n",
       "4          get_api_url                                  True\n",
       "5             get_json                                  True\n",
       "6        create_corpus                                  True\n",
       "7        corpus_format                                   csv\n",
       "8     corpus_save_path                     ../test_data/txt/\n",
       "9        csv_save_file        ../test_data/corpus/corpus.csv\n",
       "10  corpus_texts_count                                    20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 14:19:34 - INFO - Found REST API endpoint link\n",
      "2024-08-23 14:19:34 - INFO - Setting posts route https://adho.org/wp-json/wp/v2/posts\n",
      "2024-08-23 14:19:34 - INFO - Using JSON save path: ../test_data/json/\n",
      "2024-08-23 14:19:34 - INFO - Max pages to retrieve from API is set: 2\n",
      "2024-08-23 14:19:35 - INFO - Downloading https://adho.org/wp-json/wp/v2/posts?page=1\n",
      "2024-08-23 14:19:35 - INFO - Total pages to retrieve is 21\n",
      "2024-08-23 14:19:42 - INFO - Downloading https://adho.org/wp-json/wp/v2/posts?page=2\n",
      "2024-08-23 14:19:47 - INFO - Creating corpus in txt format\n",
      "2024-08-23 14:19:47 - INFO - Using corpus save path: ../test_data/txt/\n",
      "2024-08-23 14:19:47 - INFO - Creating CSV file for metadata: ../test_data/metadata/metadata.csv\n",
      "2024-08-23 14:19:47 - INFO - Processing JSON: posts-02.json\n",
      "2024-08-23 14:19:47 - INFO - Processing JSON: posts-01.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>url</td>\n",
       "      <td>https://adho.org/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>endpoint_url</td>\n",
       "      <td>https://adho.org/wp-json/wp/v2/posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>headers</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>params</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>get_api_url</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>get_json</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>create_corpus</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>corpus_format</td>\n",
       "      <td>txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>corpus_save_path</td>\n",
       "      <td>../test_data/txt/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>csv_save_file</td>\n",
       "      <td>../test_data/metadata/metadata.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>corpus_texts_count</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Key                                 Value\n",
       "0                  url                     https://adho.org/\n",
       "1         endpoint_url  https://adho.org/wp-json/wp/v2/posts\n",
       "2              headers                                  None\n",
       "3               params                                  None\n",
       "4          get_api_url                                  True\n",
       "5             get_json                                  True\n",
       "6        create_corpus                                  True\n",
       "7        corpus_format                                   txt\n",
       "8     corpus_save_path                     ../test_data/txt/\n",
       "9        csv_save_file    ../test_data/metadata/metadata.csv\n",
       "10  corpus_texts_count                                    20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "json_save_path = os.path.join(basepath_for_test_data, 'json/')\n",
    "corpus_save_path = os.path.join(basepath_for_test_data, 'txt/')\n",
    "metadata_csv_save_file = os.path.join(basepath_for_test_data, 'metadata/metadata.csv')\n",
    "corpus_csv_save_file = os.path.join(basepath_for_test_data, 'corpus/corpus.csv')\n",
    "\n",
    "# cleanup test directories\n",
    "for file in os.listdir(json_save_path):\n",
    "    os.remove(os.path.join(json_save_path, file))\n",
    "for file in os.listdir(corpus_save_path):\n",
    "    os.remove(os.path.join(corpus_save_path, file))\n",
    "for file in os.listdir(os.path.dirname(metadata_csv_save_file)):\n",
    "    os.remove(os.path.join(os.path.dirname(metadata_csv_save_file), file))\n",
    "for file in os.listdir(os.path.dirname(corpus_csv_save_file)):\n",
    "    os.remove(os.path.join(os.path.dirname(corpus_csv_save_file), file))\n",
    "\n",
    "# test a site that has no endpoint\n",
    "result = corpress(url = 'https://www.whitehouse.gov/', \n",
    "                endpoint_type='posts',\n",
    "                corpus_format='txt',\n",
    "                json_save_path = json_save_path, \n",
    "                corpus_save_path = corpus_save_path, \n",
    "                max_pages=2)\n",
    "\n",
    "assert result['get_api_url'] == True\n",
    "assert result['get_json'] == False\n",
    "assert result['create_corpus'] == False\n",
    "assert result['corpus_format'] == 'txt'\n",
    "assert result['corpus_save_path'] == corpus_save_path\n",
    "assert result['csv_save_file'] == None\n",
    "assert result['corpus_texts_count'] == 0\n",
    "\n",
    "# cleanup test directories\n",
    "for file in os.listdir(json_save_path):\n",
    "    os.remove(os.path.join(json_save_path, file))\n",
    "for file in os.listdir(corpus_save_path):\n",
    "    os.remove(os.path.join(corpus_save_path, file))\n",
    "for file in os.listdir(os.path.dirname(metadata_csv_save_file)):\n",
    "    os.remove(os.path.join(os.path.dirname(metadata_csv_save_file), file))\n",
    "for file in os.listdir(os.path.dirname(corpus_csv_save_file)):\n",
    "    os.remove(os.path.join(os.path.dirname(corpus_csv_save_file), file))\n",
    "\n",
    "# test with search params and csv format\n",
    "result = corpress(url = 'https://adho.org/', \n",
    "                endpoint_type='pages',\n",
    "                params={'search': 'conference'},\n",
    "                corpus_format='csv',\n",
    "                json_save_path = json_save_path, \n",
    "                corpus_save_path = corpus_save_path, \n",
    "                csv_save_file = corpus_csv_save_file,\n",
    "                max_pages=2)\n",
    "\n",
    "assert result['get_api_url'] == True\n",
    "assert result['get_json'] == True\n",
    "assert result['create_corpus'] == True\n",
    "assert result['corpus_format'] == 'csv'\n",
    "assert result['corpus_save_path'] == corpus_save_path\n",
    "assert result['csv_save_file'] == corpus_csv_save_file\n",
    "assert result['corpus_texts_count'] == 20\n",
    "\n",
    "# cleanup test directories\n",
    "for file in os.listdir(json_save_path):\n",
    "    os.remove(os.path.join(json_save_path, file))\n",
    "for file in os.listdir(corpus_save_path):\n",
    "    os.remove(os.path.join(corpus_save_path, file))\n",
    "for file in os.listdir(os.path.dirname(metadata_csv_save_file)):\n",
    "    os.remove(os.path.join(os.path.dirname(metadata_csv_save_file), file))\n",
    "for file in os.listdir(os.path.dirname(corpus_csv_save_file)):\n",
    "    os.remove(os.path.join(os.path.dirname(corpus_csv_save_file), file))\n",
    "\n",
    "# test txt format with metadata file\n",
    "result = corpress(url = 'https://adho.org/', \n",
    "                endpoint_type='posts',\n",
    "                corpus_format='txt',\n",
    "                json_save_path = json_save_path, \n",
    "                corpus_save_path = corpus_save_path, \n",
    "                csv_save_file = metadata_csv_save_file,\n",
    "                max_pages=2)\n",
    "\n",
    "assert result['get_api_url'] == True\n",
    "assert result['get_json'] == True\n",
    "assert result['create_corpus'] == True\n",
    "assert result['corpus_format'] == 'txt'\n",
    "assert result['corpus_save_path'] == corpus_save_path\n",
    "assert result['csv_save_file'] == metadata_csv_save_file\n",
    "assert result['corpus_texts_count'] == 20\n",
    "\n",
    "# cleanup test directories\n",
    "for file in os.listdir(json_save_path):\n",
    "    os.remove(os.path.join(json_save_path, file))\n",
    "for file in os.listdir(corpus_save_path):\n",
    "    os.remove(os.path.join(corpus_save_path, file))\n",
    "for file in os.listdir(os.path.dirname(metadata_csv_save_file)):\n",
    "    os.remove(os.path.join(os.path.dirname(metadata_csv_save_file), file))\n",
    "for file in os.listdir(os.path.dirname(corpus_csv_save_file)):\n",
    "    os.remove(os.path.join(os.path.dirname(corpus_csv_save_file), file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
